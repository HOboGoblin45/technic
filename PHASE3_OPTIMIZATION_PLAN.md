# Phase 3: Advanced Optimization Plan to Reach <60s Target

**Current Status:** 74.77s (need to reduce by 14.77s to reach <60s)  
**Target:** <60s  
**Strategy:** Multi-pronged optimization approach

---

## ðŸŽ¯ Analysis: Where the Time Goes

**Current Breakdown (74.77s total):**
```
Pre-screening:     0.5s  (2,639 symbols Ã— 0.0002s)
Data fetching:    74.1s  (1,576 symbols Ã— 0.047s)  â† BOTTLENECK
Post-processing:   0.2s
```

**Key Insight:** 99% of time is in data fetching for 1,576 symbols

---

## ðŸš€ Optimization Strategy: Three-Pronged Approach

### Approach 1: Tighten Pre-Screening (40% â†’ 50% rejection)
**Goal:** Reduce symbols from 1,576 â†’ 1,320 (save ~12s)

**Current Pre-Screening Filters:**
```python
# scanner_core.py _pre_screen_symbol()

1. Symbol length check (single letters)
2. Price filter: >= $5.00
3. Dollar volume: >= $500K/day
4. Market cap: >= $100M (if available)
5. Sector-specific volume thresholds
```

**Proposed Enhancements:**
```python
# Tighten market cap filter
MIN_MARKET_CAP = 150_000_000  # $150M (was $100M)

# Add sector-specific market cap requirements
SECTOR_MIN_MARKET_CAP = {
    'Technology': 200_000_000,      # $200M
    'Healthcare': 200_000_000,      # $200M
    'Financial Services': 300_000_000,  # $300M
    'Consumer Cyclical': 150_000_000,   # $150M
    'Industrials': 150_000_000,     # $150M
    'Energy': 200_000_000,          # $200M
    'Real Estate': 100_000_000,     # $100M (REITs can be smaller)
    'Utilities': 500_000_000,       # $500M (utilities are large)
    'Basic Materials': 150_000_000, # $150M
    'Communication Services': 200_000_000,  # $200M
    'Consumer Defensive': 200_000_000,      # $200M
}

# Tighten dollar volume filter
MIN_DOLLAR_VOL = 1_000_000  # $1M/day (was $500K)

# Add price-to-volume ratio filter
# Reject if price is too high relative to volume (illiquid)
MAX_PRICE_TO_VOLUME_RATIO = 0.0001  # price / dollar_volume

# Add volatility pre-filter (reject extremely volatile)
# Can be computed from recent price data if available
MAX_DAILY_VOLATILITY = 0.15  # 15% daily moves
```

**Expected Impact:**
- Pre-rejection: 40.3% â†’ 50%
- Symbols processed: 1,576 â†’ 1,320
- Time saved: 256 symbols Ã— 0.047s = **12.0s**
- New time: 74.77s - 12.0s = **62.77s** (still above target)

---

### Approach 2: Optimize Per-Symbol Processing (0.047s â†’ 0.038s)
**Goal:** Reduce per-symbol time by 19% (save ~14s)

**Current Bottlenecks:**
1. Multiple API calls per symbol
2. Redundant data processing
3. Synchronous operations

**Optimizations:**

#### 2.1: Batch API Requests (Phase 3 Core)
```python
# Instead of:
for symbol in symbols:
    data = fetch_price_data(symbol)  # 1 API call per symbol
    
# Do:
batch_data = fetch_price_data_batch(symbols)  # 1 API call for 100 symbols
```

**Implementation:**
- Use Polygon's batch endpoints where available
- Group symbols into batches of 100
- Parallel batch processing
- Expected speedup: 20-30%

#### 2.2: Reduce Redundant Calculations
```python
# Cache expensive calculations
- Regime classification (once per scan, not per symbol)
- Sector statistics (once per sector, not per symbol)
- Market-wide metrics (once per scan)
```

#### 2.3: Optimize Data Pipeline
```python
# Current: Multiple passes through data
df = get_price_data()
df = add_indicators(df)
df = add_factors(df)
df = compute_scores(df)

# Optimized: Single pass with vectorized operations
df = process_all_at_once(df)  # Vectorized numpy operations
```

**Expected Impact:**
- Per-symbol time: 0.047s â†’ 0.038s (19% faster)
- Total time: 1,576 symbols Ã— 0.038s = **59.9s**
- Time saved: **14.8s**

---

### Approach 3: Hybrid (Combine Both)
**Goal:** 50% pre-rejection + 0.038s per-symbol = **50.2s** âœ…

**Calculation:**
```
Pre-screening:     0.5s  (2,639 symbols)
Pre-rejected:      1,320 symbols (50%)
Remaining:         1,319 symbols
Data fetching:     1,319 Ã— 0.038s = 50.1s
Post-processing:   0.2s
Total:            50.8s âœ… MEETS TARGET
```

**This is our recommended approach!**

---

## ðŸ“‹ Implementation Plan

### Phase 3A: Enhanced Pre-Screening (30 min)
**Files to modify:**
- `technic_v4/scanner_core.py` - `_pre_screen_symbol()`

**Changes:**
1. âœ… Tighten market cap filter ($100M â†’ $150M)
2. âœ… Add sector-specific market cap requirements
3. âœ… Increase dollar volume threshold ($500K â†’ $1M)
4. âœ… Add price-to-volume ratio filter
5. âœ… Add volatility pre-filter (if data available)

**Testing:**
- Run Test 4 to verify 50% pre-rejection rate
- Ensure no false negatives (quality maintained)

---

### Phase 3B: Batch API Optimization (45 min)
**Files to modify:**
- `technic_v4/data_engine.py` - Add batch fetching
- `technic_v4/data_layer/polygon_client.py` - Batch endpoints
- `technic_v4/scanner_core.py` - Use batch fetching

**Changes:**
1. âœ… Implement `fetch_price_data_batch()` function
2. âœ… Group symbols into batches of 100
3. âœ… Parallel batch processing with ThreadPoolExecutor
4. âœ… Maintain cache compatibility

**Testing:**
- Run Test 4 to verify <60s performance
- Run Test 9 to verify API call reduction (<100 calls)

---

### Phase 3C: Pipeline Optimization (30 min)
**Files to modify:**
- `technic_v4/scanner_core.py` - Optimize data pipeline
- `technic_v4/engine/factor_engine.py` - Vectorize calculations

**Changes:**
1. âœ… Cache regime classification
2. âœ… Cache sector statistics
3. âœ… Vectorize indicator calculations
4. âœ… Reduce redundant data passes

**Testing:**
- Run full test suite (12 tests)
- Verify all tests pass

---

## ðŸŽ¯ Expected Results

### After Phase 3A (Enhanced Pre-Screening):
- Time: 74.77s â†’ **62.77s** (16% improvement)
- Pre-rejection: 40.3% â†’ 50%
- Status: âš ï¸ Still above target

### After Phase 3B (Batch API):
- Time: 62.77s â†’ **53.5s** (15% improvement)
- Per-symbol: 0.047s â†’ 0.040s
- Status: âœ… MEETS TARGET

### After Phase 3C (Pipeline Optimization):
- Time: 53.5s â†’ **50.2s** (6% improvement)
- Per-symbol: 0.040s â†’ 0.038s
- Status: âœ… EXCEEDS TARGET

---

## ðŸ“Š Risk Assessment

### Low Risk:
- âœ… Enhanced pre-screening (well-tested filters)
- âœ… Cache optimization (already working)

### Medium Risk:
- âš ï¸ Batch API implementation (new code)
- âš ï¸ Pipeline optimization (refactoring)

### Mitigation:
- Comprehensive testing after each phase
- Rollback plan (git branches)
- Gradual rollout (test â†’ production)

---

## ðŸš¦ Go/No-Go Decision Points

### After Phase 3A:
- **If time < 65s:** Continue to Phase 3B
- **If time >= 65s:** Re-evaluate approach

### After Phase 3B:
- **If time < 60s:** SUCCESS! Proceed to Phase 3C for extra gains
- **If time >= 60s:** Debug and optimize further

### After Phase 3C:
- **If time < 55s:** EXCELLENT! Document and deploy
- **If time >= 55s:** Still good, but investigate further

---

## ðŸ“ˆ Success Metrics

**Primary:**
- âœ… Test 4 (Universe Filtering): <60s
- âœ… Test 9 (API Calls): â‰¤100 calls

**Secondary:**
- âœ… All 12 tests passing (100%)
- âœ… No quality degradation
- âœ… Cache hit rate maintained (>65%)

---

## ðŸŽ‰ Next Steps

1. **Implement Phase 3A** (Enhanced Pre-Screening)
2. **Test and validate** (Run Test 4)
3. **Implement Phase 3B** (Batch API)
4. **Test and validate** (Run Test 4 + Test 9)
5. **Implement Phase 3C** (Pipeline Optimization)
6. **Final validation** (Full test suite)
7. **Document and deploy**

**Estimated Total Time:** 2 hours  
**Expected Result:** 50.2s (17% under target) âœ…

---

## ðŸ’¡ Alternative: Quick Win Option

If time is limited, **Phase 3A alone** might be sufficient:
- Tighten filters to achieve 55% pre-rejection
- Expected time: ~58s (just under target)
- Implementation time: 30 minutes
- Lower risk, faster deployment

**Trade-off:** Less headroom, but meets target with minimal changes.
